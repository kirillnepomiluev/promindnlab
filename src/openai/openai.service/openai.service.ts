import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import OpenAI from 'openai';
import { TextContentBlock } from 'openai/resources/beta/threads/messages';

@Injectable()
export class OpenAiService {
  private readonly openAi: OpenAI;
  private readonly logger = new Logger(OpenAiService.name);
  private threadMap: Map<number, string> = new Map();

  constructor(private readonly configService: ConfigService) {
    const rawKey = this.configService.get<string>('OPENAI_API_KEY_PRO');
    if (!rawKey) {
      throw new Error('–ù–µ –∑–∞–¥–∞–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY_PRO');
    }
    this.logger.debug(`Raw OpenAI API key length: ${rawKey.length}`);
    this.logger.debug(
      `API raw key fragment: ${rawKey.slice(0, 5)}...${rawKey.slice(-5)}`,
    );
    // –£–¥–∞–ª—è–µ–º BOM –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
    const key = rawKey.replace(/\s+/g, '').trim();
    this.logger.debug(
      `API key fragment: ${key.slice(0, 5)}...${key.slice(-5)}`,
    );
    this.logger.debug(`Sanitized OpenAI API key length: ${key.length}`);

    const baseURL =
      this.configService.get<string>('OPENAI_BASE_URL_PRO')?.trim() ||
      'https://chat.neurolabtg.ru/v1';

    this.openAi = new OpenAI({
      apiKey: key,
      baseURL,
    });
  }
  async waitForRunCompletion(threadId: string, runId: string) {
    let runStatus = 'in_progress';

    while (runStatus === 'in_progress' || runStatus === 'queued') {
      console.log(`–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è run ${runId}...`);
      await new Promise((res) => setTimeout(res, 3000)); // –ñ–¥—ë–º 3 —Å–µ–∫—É–Ω–¥—ã –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π

      const run = await this.openAi.beta.threads.runs.retrieve(threadId, runId);
      runStatus = run.status;
    }

    console.log(`Run ${runId} –∑–∞–≤–µ—Ä—à–µ–Ω —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º: ${runStatus}`);
  }

  async chat(content: string, userId: number) {
    let threadId = this.threadMap.get(userId);
    let thread: { id: string };
    const assistantId = 'asst_naDxPxcSCe4YgEW3S7fXf4wd';
    try {
      if (!threadId) {
        // –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç—Ä–µ–¥, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        thread = await this.openAi.beta.threads.create();

        threadId = thread.id;
        this.threadMap.set(userId, threadId);
      } else {
        // –ï—Å–ª–∏ —Ç—Ä–µ–¥ —É–∂–µ –µ—Å—Ç—å, –ø—Ä–æ—Å—Ç–æ –ø–æ–ª—É—á–∞–µ–º –µ–≥–æ ID
        thread = { id: threadId };
      }
      // === –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∞–∫—Ç–∏–≤–Ω—ã–π run ===
      const runs = await this.openAi.beta.threads.runs.list(threadId);
      const activeRun = runs.data.find(
        (run) => run.status === 'in_progress' || run.status === 'queued',
      );

      if (activeRun) {
        console.log(
          `–ê–∫—Ç–∏–≤–Ω—ã–π run —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–ª—è thread ${threadId}. –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è...`,
        );
        await this.waitForRunCompletion(threadId, activeRun.id);
      }

      // –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ç—Ä–µ–¥
      await this.openAi.beta.threads.messages.create(thread.id, {
        role: 'user',
        content: content,
      });

      // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–æ —Ç—Ä–µ–¥—É
      const response = await this.openAi.beta.threads.runs.createAndPoll(
        thread.id,
        {
          assistant_id: assistantId,
        },
      );
      if (response.status === 'completed') {
        // const tokensUsed = response.usage?.total_tokens ?? 0;

        const messages = await this.openAi.beta.threads.messages.list(
          response.thread_id,
        );
        // for (const message of messages.data.reverse()) {
        //   //console.log(`${message.role} > ${message.content[0].text.value}`);
        // }

        const assistantMessage = messages.data[0];
        if (assistantMessage.content[0].type == 'text') {
          const answer: TextContentBlock = assistantMessage.content[0];

          return answer.text.value;
        }
      } else {
        console.log(response.status);
      }

      // –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ response —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∞—Å—Å–∏–≤ messages,
      // –≥–¥–µ –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç - –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    } catch (error) {
      console.error(error);
      console.log(error);
      return 'ü§ñ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç OpenAI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ';
    }
  }

  async generateImage(prompt: string): Promise<string | Buffer | null> {
    try {
      const { data } = await this.openAi.images.generate({
        model: 'gpt-image-1',
        prompt,
        quality: 'low',
        n: 1,
        size: '1024x1024',
      });
      if (!data || data.length === 0) {
        this.logger.error('Image.generate –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π data', data);
        return null;
      }
      const img = data[0];
      // –û—Å–Ω–æ–≤–Ω–æ–π —Å–ª—É—á–∞–π: –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ base64-JSON
      if ('b64_json' in img && img.b64_json) {
        return Buffer.from(img.b64_json, 'base64');
      }
      // –ù–∞ —Å–ª—É—á–∞–π –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º URL
      if ('url' in img && img.url) {
        return img.url;
      }
      this.logger.error('Image data –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∏ b64_json, –Ω–∏ url', img);
      return null;
    } catch (err: any) {
      this.logger.error('–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è', err);
      return null;
    }
  }
}
